{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open (\"./feats/all_spliced.txt\") as feature_file:\n",
    "    train_features = feature_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./alis/gzs/ali.post2\") as train_labels:\n",
    "    train_labels = train_labels.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_labels = []\n",
    "use = \"train\"\n",
    "for line in train_labels:\n",
    "    labels_list = line.strip().split(\"[\")\n",
    "    labels_list = [re.sub(\"\\]\", \"\", ele.strip()).strip().split()[0] for ele in labels_list]\n",
    "    speaker_id, sentence_id = labels_list[0].split(\"_\")\n",
    "    alis_post = np.array([int(ele) for ele in labels_list[1:]])\n",
    "    frame_number = 1\n",
    "    for label in alis_post:\n",
    "        final_labels.append([speaker_id, sentence_id, frame_number, use, label])\n",
    "        frame_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels_final = []\n",
    "# for i in final_labels:\n",
    "#     for j in i:\n",
    "#         labels_final.append(int(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame_number = 1\n",
    "use = \"train\"\n",
    "dummy_np = []\n",
    "for line in train_features:\n",
    "    line = re.sub(\" \\[\", \"\", line.strip())\n",
    "    line = re.sub(\" \\]\", \"\", line.strip())\n",
    "    if(\"_\" in line):\n",
    "        speaker_id, sentence_id = line.split(\"_\")\n",
    "        frame_number = 1\n",
    "    else:\n",
    "        mfcc = [float(ele) for ele in line.split(\" \")]\n",
    "        dummy_np.append([speaker_id, sentence_id, frame_number, use, mfcc, \"None\"])\n",
    "        frame_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(columns=[\"speaker_id\", \"sentence_id\", \"frame_number\", \"use\", \"feature_vector\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speaker_ids = [ele[0] for ele in dummy_np]\n",
    "sentence_ids = [ele[1] for ele in dummy_np]\n",
    "frame_numbers = [ele[2] for ele in dummy_np]\n",
    "use = [ele[3] for ele in dummy_np]\n",
    "features = [ele[4] for ele in dummy_np]\n",
    "label = [ele[5] for ele in dummy_np]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_df[\"speaker_id\"] = speaker_ids\n",
    "feature_df[\"sentence_id\"] = sentence_ids \n",
    "feature_df[\"frame_number\"] = frame_numbers\n",
    "feature_df[\"use\"] = use \n",
    "feature_df[\"feature_vector\"] = features\n",
    "feature_df[\"label\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_df = pd.DataFrame(columns=[\"speaker_id\", \"sentence_id\", \"frame_number\", \"use\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speaker_ids = [ele[0] for ele in final_labels]\n",
    "sentence_ids = [ele[1] for ele in final_labels]\n",
    "frame_numbers = [ele[2] for ele in final_labels]\n",
    "use = [ele[3] for ele in final_labels]\n",
    "label = [ele[4] for ele in final_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_df[\"speaker_id\"] = speaker_ids\n",
    "label_df[\"sentence_id\"] = sentence_ids \n",
    "label_df[\"frame_number\"] = frame_numbers\n",
    "label_df[\"use\"] = use \n",
    "label_df[\"label\"] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_df.to_pickle(\"raw_feats.pkl\")\n",
    "label_df.to_pickle(\"raw_labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.merge(feature_df, label_df,  how='inner', left_on=['speaker_id','sentence_id', 'frame_number'], right_on = ['speaker_id','sentence_id', 'frame_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = new_df.drop(\"label_x\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df = new_df.drop(\"use_x\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in new_df:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.columns = [\"speaker_id\", \"sentence_id\", \"frame_number\", \"feature_vector\", \"use\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(new_df[\"label\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append_features(Xtrain):\n",
    "    new_Xtrain = []\n",
    "    zero_array = np.zeros((1,40))[0]\n",
    "    for i in range(len(Xtrain)):\n",
    "        if(i==0):\n",
    "            new_Xtrain.append(np.hstack((zero_array,zero_array,zero_array,zero_array,zero_array,Xtrain[i],Xtrain[i+1],Xtrain[i+2],Xtrain[i+3],Xtrain[i+4],Xtrain[i+5])))\n",
    "        elif(i==1):\n",
    "            new_Xtrain.append(np.hstack((zero_array,zero_array,zero_array,zero_array,Xtrain[i-1],Xtrain[i],Xtrain[i+1],Xtrain[i+2],Xtrain[i+3],Xtrain[i+4],Xtrain[i+5])))\n",
    "        elif(i==2):\n",
    "            new_Xtrain.append(np.hstack((zero_array,zero_array,zero_array,Xtrain[i-2],Xtrain[i-1],Xtrain[i],Xtrain[i+1],Xtrain[i+2],Xtrain[i+3],Xtrain[i+4],Xtrain[i+5])))\n",
    "        elif(i==3):\n",
    "            new_Xtrain.append(np.hstack((zero_array,zero_array,Xtrain[i-3],Xtrain[i-2],Xtrain[i-1],Xtrain[i],Xtrain[i+1],Xtrain[i+2],Xtrain[i+3],Xtrain[i+4],Xtrain[i+5])))\n",
    "        elif(i==4):\n",
    "            new_Xtrain.append(np.hstack((zero_array,Xtrain[i-4],Xtrain[i-3],Xtrain[i-2],Xtrain[i-1],Xtrain[i],Xtrain[i+1],Xtrain[i+2],Xtrain[i+3],Xtrain[i+4],Xtrain[i+5])))\n",
    "\n",
    "        elif(i==len(Xtrain)-5):\n",
    "            new_Xtrain.append(np.hstack((Xtrain[i-5],Xtrain[i-4],Xtrain[i-3],Xtrain[i-2],Xtrain[i-1],Xtrain[i],Xtrain[i+1],Xtrain[i+2],Xtrain[i+3],Xtrain[i+4],zero_array)))\n",
    "        elif(i==len(Xtrain)-4):\n",
    "            new_Xtrain.append(np.hstack((Xtrain[i-5],Xtrain[i-4],Xtrain[i-3],Xtrain[i-2],Xtrain[i-1],Xtrain[i],Xtrain[i+1],Xtrain[i+2],Xtrain[i+3],zero_array,zero_array)))\n",
    "        elif(i==len(Xtrain)-3):\n",
    "            new_Xtrain.append(np.hstack((Xtrain[i-5],Xtrain[i-4],Xtrain[i-3],Xtrain[i-2],Xtrain[i-1],Xtrain[i],Xtrain[i+1],Xtrain[i+2],zero_array,zero_array,zero_array)))\n",
    "        elif(i==len(Xtrain)-2):\n",
    "            new_Xtrain.append(np.hstack((Xtrain[i-5],Xtrain[i-4],Xtrain[i-3],Xtrain[i-2],Xtrain[i-1],Xtrain[i],Xtrain[i+1],zero_array,zero_array,zero_array,zero_array)))\n",
    "        elif(i==len(Xtrain)-1):\n",
    "            new_Xtrain.append(np.hstack((Xtrain[i-5],Xtrain[i-4],Xtrain[i-3],Xtrain[i-2],Xtrain[i-1],Xtrain[i],zero_array,zero_array,zero_array,zero_array,zero_array)))\n",
    "\n",
    "            \n",
    "        else:\n",
    "            new_Xtrain.append(np.hstack((Xtrain[i-5],Xtrain[i-4],Xtrain[i-3],Xtrain[i-2],Xtrain[i-1],Xtrain[i],Xtrain[i+1],Xtrain[i+2],Xtrain[i+3],Xtrain[i+4],Xtrain[i+5])))\n",
    "        if(i%100000 == 0):\n",
    "            print(i)\n",
    "    return(new_Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new_df[\"feature_vector\"] = append_features(new_df[\"feature_vector\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(new_df[\"feature_vector\"].tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(new_df[\"feature_vector\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df[\"label\"].tolist()[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.to_hdf(\"kaldi_spliced_440_post_new.hd5\", key=\"timit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.memory_usage(deep=True).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
